{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy\n",
    "import plotly.express as px\n",
    "from scipy.stats import mstats\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "import csv\n",
    "#pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in dataset and isolation regions from hierarchy ID file\n",
    "path=\"/Users/danielblanco/Documents/Mortality_Project/data/2_projection/3_impacts/main_specification/raw/single/rcp85/CCSM4/low/SSP3/\"\n",
    "file1=\"Agespec_interaction_GMFD_POLY-4_TINV_CYA_NW_w1-oldest-aggregated.nc4\"\n",
    "file2=\"Agespec_interaction_GMFD_POLY-4_TINV_CYA_NW_w1-oldest-histclim-aggregated.nc4\"\n",
    "\n",
    "ds = xr.open_dataset(path+file1)\n",
    "# ds = xr.open_dataset(file1) \n",
    "ds1 = xr.open_dataset(path+file2)\n",
    "# ds1 = xr.open_dataset(file2)\n",
    "\n",
    "\n",
    "\n",
    "df = ds.to_dataframe()\n",
    "df1 = ds1.to_dataframe()\n",
    "#DEL = c    #multiple versions for Dehli in aggregated version\n",
    "OSL = df.loc[df['regions'] =='NOR.12']\n",
    "CHI = df.loc[df['regions'] =='USA.14']        #listed as 'Cook' county\n",
    "SPB = df.loc[df['regions'] =='BRA']  #double check aggregated version, unaggreagted version not listed as sao paulo\n",
    "ACC = df.loc[df['regions'] =='GHA.5']\n",
    "SYD = df.loc[df['regions'] =='AUS.4']    #unaggreageted version split into \n",
    "BEI = df.loc[df['regions'] == 'CHN.2']     #double check aggregated version, unaggregated version only has Miyun district\n",
    "DEL1 = df1.loc[df['regions'] =='IND.10']\n",
    "OSL1 = df1.loc[df['regions'] =='NOR.12']\n",
    "CHI1 = df1.loc[df['regions'] =='USA.14']        \n",
    "SPB1 = df1.loc[df['regions'] =='BRA']  \n",
    "ACC1 = df1.loc[df['regions'] =='GHA.5']\n",
    "SYD1 = df1.loc[df['regions'] =='AUS.4']    \n",
    "BEI1 = df1.loc[df['regions'] == 'CHN.2']\n",
    "\n",
    "\n",
    "# #take last 30yrs of diff (as an example), flatten it (use flatten function)\n",
    "# #one dimension is years of del, and years of del 1, want the difference between last 20 yrs of both\n",
    "# #del - del1, for last 30 years\n",
    "# #for loop to iterate for all time series (30yr windows)\n",
    "# #take 30yr window in for loop, do meshgrid, then flatten, center = true\n",
    "# #will extract climate signal, when does it emerge from 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy var\n",
    "# xx,yy = np.meshgrid(ACC['rebased'],ACC1['rebased'])\n",
    "\n",
    "# Extract the \"rebased\" variable\n",
    "xx=ACC['rebased'] \n",
    "yy=ACC1['rebased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year and region info from xx\n",
    "xx_idx=xx.index.values.tolist()\n",
    "\n",
    "xx_year=[]\n",
    "xx_region=[]\n",
    "\n",
    "for t in xx_idx:\n",
    "    xx_year.append(t[0])\n",
    "    xx_region.append(t[1])\n",
    "\n",
    "# Extract the \"rebased\" values\n",
    "xx_rebased=xx.values\n",
    "yy_rebased=yy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=30\n",
    "tot_len=len(xx_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the pair wise difference with a 30 year sliding window.\n",
    "xxreb_yyreb=np.empty((0, step)) #setup empty ndarray\n",
    "xx_year_win=np.empty((0, 2)) #setup empty ndarray\n",
    "\n",
    "# loop the 30yr window over timeseries\n",
    "for ii in range(tot_len):\n",
    "    if ii == (tot_len - step):\n",
    "        break #break loop if it exceeds window.\n",
    "    else:\n",
    "        # Sliding window subtraction \n",
    "        dum1=xx_rebased[ii:ii+step] - yy_rebased[ii:ii+step]\n",
    "        xxreb_yyreb=np.vstack((xxreb_yyreb, dum1))\n",
    "\n",
    "        dum2 = np.hstack((xx_year[ii], xx_year[ii+step]))\n",
    "        xx_year_win=np.vstack((xx_year_win,dum2))\n",
    "\n",
    "del dum1, dum2      # clear dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
